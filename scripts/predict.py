#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Predict top-3 probability for horses in a new race using trained XGBoost model.
Input: CSV file with horse info for a single race.
Output: Sorted list of horses with predicted probabilities.
Author: Your Name
Date: 2026-01-02
"""

import pandas as pd
import numpy as np
import joblib
import argparse
import os
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ===== æ¬„ä½æ˜ å°„ï¼ˆèˆ‡ build_dataset.py ä¸€è‡´ï¼‰=====
INPUT_COLUMN_MAPPING = {
    'é¦¬å': 'horse_name',
    'é¨å¸«': 'jockey',
    'ç·´é¦¬å¸«': 'trainer',
    'å¯¦éš›è² ç£…': 'actual_weight',
    'æ’ä½é«”é‡': 'declared_weight',
    'æª”ä½': 'draw',
    'ç¨è´è³ ç‡': 'win_odds',
    # æ”¯æ´è‹±æ–‡æ¬„ä½ï¼ˆå¯é¸ï¼‰
    'Horse': 'horse_name',
    'Jockey': 'jockey',
    'Trainer': 'trainer',
    'Weight': 'actual_weight',
    'Draw': 'draw',
    'Odds': 'win_odds',
}

def load_model_and_mappings(model_path: str):
    """è¼‰å…¥æ¨¡å‹èˆ‡ç·¨ç¢¼æ˜ å°„ï¼ˆå¾è¨“ç·´æ•¸æ“šæ¨æ–·ï¼‰"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
    
    model = joblib.load(model_path)
    logger.info(f"âœ… è¼‰å…¥æ¨¡å‹: {model_path}")
    
    # å¾æ¨¡å‹ç²å–ç‰¹å¾µé †åº
    expected_features = model.feature_names_in_
    logger.info(f"æ¨¡å‹é æœŸç‰¹å¾µ: {list(expected_features)}")
    
    return model, expected_features

def prepare_input_data(input_df: pd.DataFrame, expected_features):
    """å°‡è¼¸å…¥æ•¸æ“šè½‰æ›ç‚ºæ¨¡å‹æ‰€éœ€æ ¼å¼"""
    df = input_df.copy()
    
    # 1. æ‡‰ç”¨æ¬„ä½æ˜ å°„
    df = df.rename(columns=INPUT_COLUMN_MAPPING)
    
    # 2. é©—è­‰å¿…è¦æ¬„ä½
    required_cols = ['horse_name', 'jockey', 'trainer', 'actual_weight', 'win_odds']
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        raise ValueError(f"è¼¸å…¥æ•¸æ“šç¼ºå°‘å¿…è¦æ¬„ä½: {missing}. è«‹ç¢ºèª CSV åŒ…å«: {required_cols}")
    
    # 3. æ•¸å€¼è½‰æ›
    numeric_cols = ['actual_weight', 'declared_weight', 'draw', 'win_odds']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # 4. è™•ç†ç¼ºå¤±æ•¸å€¼ï¼ˆç”¨ä¸­ä½æ•¸æˆ–é»˜èªå€¼ï¼‰
    if 'declared_weight' in df.columns and df['declared_weight'].isna().any():
        df['declared_weight'] = df['declared_weight'].fillna(df['declared_weight'].median())
    if 'draw' in df.columns and df['draw'].isna().any():
        df['draw'] = df['draw'].fillna(df['draw'].median())
    
    # 5. ç”Ÿæˆ ID ç·¨ç¢¼ï¼ˆæ¨¡æ“¬è¨“ç·´æ™‚çš„ Categorical ç·¨ç¢¼ï¼‰
    # æ³¨æ„ï¼šæœªçŸ¥é¡åˆ¥è¨­ç‚º -1ï¼ˆèˆ‡è¨“ç·´ä¸€è‡´ï¼‰
    cat_mappings = {}
    for cat_col in ['horse_name', 'jockey', 'trainer']:
        if f"{cat_col}_id" in expected_features:
            # å‡è¨­æˆ‘å€‘ç„¡æ³•å–å¾—å®Œæ•´æ˜ å°„ â†’ ç”¨è‡¨æ™‚ç·¨ç¢¼ï¼ˆåƒ…é™æœ¬æ¬¡é æ¸¬ï¼‰
            df[f"{cat_col}_id"] = pd.Categorical(df[cat_col]).codes
    
    # 6. é¸å–æ¨¡å‹éœ€è¦çš„ç‰¹å¾µ
    available_features = [f for f in expected_features if f in df.columns]
    X = df[available_features].copy()
    
    # 7. ç¢ºä¿ç‰¹å¾µé †åºèˆ‡è¨“ç·´æ™‚ä¸€è‡´
    X = X.reindex(columns=expected_features, fill_value=-1)  # æœªçŸ¥ç‰¹å¾µå¡« -1
    
    logger.info(f"æº–å‚™å¥½ {len(X)} åŒ¹é¦¬çš„é æ¸¬æ•¸æ“š")
    return X, df[['horse_name', 'jockey', 'trainer', 'win_odds']]

def main(input_csv: str, model_path: str, output_csv: str = None):
    # 1. è¼‰å…¥æ¨¡å‹
    model, expected_features = load_model_and_mappings(model_path)
    
    # 2. è®€å–è¼¸å…¥æ•¸æ“š
    if not os.path.exists(input_csv):
        raise FileNotFoundError(f"è¼¸å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv}")
    
    input_df = pd.read_csv(input_csv)
    logger.info(f"è®€å–è¼¸å…¥æ•¸æ“š: {input_csv} ({len(input_df)} åŒ¹é¦¬)")
    
    # 3. æº–å‚™ç‰¹å¾µ
    X, meta_df = prepare_input_data(input_df, expected_features)
    
    # 4. é æ¸¬
    proba = model.predict_proba(X)[:, 1]  # å…¥ä½æ©Ÿç‡ (class=1)
    predictions = pd.DataFrame({
        'horse_name': meta_df['horse_name'],
        'jockey': meta_df['jockey'],
        'trainer': meta_df['trainer'],
        'win_odds': meta_df['win_odds'],
        'top3_probability': proba
    })
    
    # 5. æ’åºï¼ˆé«˜æ©Ÿç‡åœ¨å‰ï¼‰
    predictions = predictions.sort_values('top3_probability', ascending=False).reset_index(drop=True)
    predictions['rank'] = predictions.index + 1
    
    # 6. è¼¸å‡º
    if output_csv:
        predictions.to_csv(output_csv, index=False, encoding='utf-8-sig')
        logger.info(f"é æ¸¬çµæœå·²å„²å­˜è‡³: {output_csv}")
    
    # 7. åˆ—å°åˆ°çµ‚ç«¯ï¼ˆç¾è§€æ ¼å¼ï¼‰
    print("\n" + "="*70)
    print("ğŸ‡ è³½é¦¬å…¥ä½æ©Ÿç‡é æ¸¬çµæœ")
    print("="*70)
    for _, row in predictions.iterrows():
        print(f"#{row['rank']:2d} | æ©Ÿç‡: {row['top3_probability']:.2%} | "
              f"é¦¬: {row['horse_name']} | é¨å¸«: {row['jockey']} | "
              f"è³ ç‡: {row['win_odds']:.1f}")
    print("="*70)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é æ¸¬æ–°è³½äº‹é¦¬åŒ¹å…¥ä½æ©Ÿç‡")
    parser.add_argument(
        "--input",
        required=True,
        help="è¼¸å…¥ CSV è·¯å¾‘ï¼ˆåŒ…å«ä¸€å ´æ¯”è³½çš„æ‰€æœ‰é¦¬åŒ¹è³‡è¨Šï¼‰"
    )
    parser.add_argument(
        "--model",
        default="models/xgb_model.pkl",
        help="è¨“ç·´å¥½çš„æ¨¡å‹è·¯å¾‘"
    )
    parser.add_argument(
        "--output",
        help="è¼¸å‡ºé æ¸¬çµæœ CSV è·¯å¾‘ï¼ˆå¯é¸ï¼‰"
    )
    
    args = parser.parse_args()
    main(args.input, args.model, args.output)