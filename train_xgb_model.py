# train_xgb_model.py â€”â€” å®Œæ•´ç‰ˆï¼šå« Optuna èª¿åƒ + å„²å­˜ feature_names.pkl

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from xgboost import XGBClassifier
import joblib
import optuna

# å…¨åŸŸè®Šæ•¸ï¼ˆä¾› objective å‡½æ•¸ä½¿ç”¨ï¼‰
X_global = None
y_global = None

def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 500),
        "max_depth": trial.suggest_int("max_depth", 3, 8),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
        "reg_alpha": trial.suggest_float("reg_alpha", 0, 10),
        "reg_lambda": trial.suggest_float("reg_lambda", 0, 10),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
        "random_state": 42,
        "eval_metric": "logloss",
        "use_label_encoder": False,
    }

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    auc_scores = []

    for train_idx, val_idx in cv.split(X_global, y_global):
        X_train_fold, X_val_fold = X_global.iloc[train_idx], X_global.iloc[val_idx]
        y_train_fold, y_val_fold = y_global.iloc[train_idx], y_global.iloc[val_idx]

        model = XGBClassifier(**params)
        model.fit(
            X_train_fold,
            y_train_fold,
            eval_set=[(X_val_fold, y_val_fold)],
            verbose=0,
        )
        y_pred = model.predict_proba(X_val_fold)[:, 1]
        auc = roc_auc_score(y_val_fold, y_pred)
        auc_scores.append(auc)

    return np.mean(auc_scores)

def main():
    global X_global, y_global

    print("ğŸ”„ æ­£åœ¨è®€å– historical_races.csv...")
    df = pd.read_csv("historical_races.csv")
    print(f"ğŸ“Š åŸå§‹è³‡æ–™å½¢ç‹€: {df.shape}")

    # ç§»é™¤éå¿…è¦æ¬„ä½
    cols_to_drop = ["race_date", "horse_name"]
    df = df.drop(columns=cols_to_drop, errors='ignore')
    print(f"âœ… å·²ç§»é™¤æ¬„ä½: {cols_to_drop}")

    # åˆ†é›¢ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸ï¼ˆé—œéµï¼ç›®æ¨™æ˜¯ 'is_top3'ï¼‰
    if "is_top3" not in df.columns:
        raise ValueError("âŒ è³‡æ–™ä¸­ç¼ºå°‘ 'is_top3' æ¬„ä½ï¼")

    y = df["is_top3"]          # ğŸ‘ˆ æ­£ç¢ºçš„ç›®æ¨™è®Šæ•¸
    X = df.drop(columns=["is_top3"])  # ğŸ‘ˆ ç§»é™¤ç›®æ¨™è®Šæ•¸

    # ç·¨ç¢¼é¡åˆ¥è®Šæ•¸
    categorical_cols = ["jockey", "trainer", "track_condition", "class"]
    encoders = {}
    for col in categorical_cols:
        if col in X.columns:
            le = LabelEncoder()
            X[col] = X[col].fillna("æœªçŸ¥").astype(str)
            X[col] = le.fit_transform(X[col])
            encoders[col] = le

    # ç¢ºä¿ç„¡ object å‹æ…‹
    object_cols = X.select_dtypes(include=['object']).columns.tolist()
    if object_cols:
        raise ValueError(f"âŒ ä»æœ‰ object å‹æ¬„ä½: {object_cols}")

    print(f"âœ… æœ€çµ‚ç‰¹å¾µçŸ©é™£å½¢ç‹€: {X.shape}")
    print("ä½¿ç”¨ç‰¹å¾µ:", list(X.columns))

    # è¨­å®šå…¨åŸŸè®Šæ•¸ä¾› Optuna ä½¿ç”¨
    X_global = X
    y_global = y

    # ====== è¶…åƒæ•¸èª¿å„ª ======
    print("\nğŸ” é–‹å§‹ Optuna è¶…åƒæ•¸èª¿å„ªï¼ˆç›®æ¨™ï¼šæœ€å¤§åŒ– AUCï¼‰...")
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=30)  # å¯èª¿æ•´è©¦é©—æ¬¡æ•¸

    print(f"\nğŸ¯ æœ€ä½³ AUC: {study.best_value:.4f}")
    print("æœ€ä½³åƒæ•¸:")
    for k, v in study.best_params.items():
        print(f"  {k}: {v}")

    # ====== è¨“ç·´æœ€çµ‚æ¨¡å‹ ======
    best_params = study.best_params
    best_params.update({
        "random_state": 42,
        "eval_metric": "logloss",
        "use_label_encoder": False,
    })

    print("\nğŸš€ ä½¿ç”¨æœ€ä½³åƒæ•¸è¨“ç·´æœ€çµ‚æ¨¡å‹...")
    final_model = XGBClassifier(**best_params)
    final_model.fit(X, y)

    # è©•ä¼°å…¨è³‡æ–™ AUC
    y_pred_full = final_model.predict_proba(X)[:, 1]
    full_auc = roc_auc_score(y, y_pred_full)
    print(f"âœ… æœ€çµ‚æ¨¡å‹ AUC (å…¨è³‡æ–™): {full_auc:.4f}")

    # ====== å„²å­˜æ‰€æœ‰å¿…è¦æª”æ¡ˆ ======
    joblib.dump(final_model, "model.pkl")
    joblib.dump(encoders, "label_encoders.pkl")
    joblib.dump(list(X.columns), "feature_names.pkl")  # ğŸ‘ˆ é—œéµï¼ä¾› SHAP å’Œ Streamlit ä½¿ç”¨

    print("\nğŸ’¾ å·²å„²å­˜:")
    print("   - model.pkl")
    print("   - label_encoders.pkl")
    print("   - feature_names.pkl")

if __name__ == "__main__":
    main()
