import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
from pathlib import Path

# ==============================
# 1. è¼‰å…¥æ‰€æœ‰ Excel è³½æœæª”æ¡ˆ
# ==============================
def load_race_results(file_paths):
    all_races = []
    for file in file_paths:
        df = pd.read_excel(file)
        # å‡è¨­æ¯å ´æ¯”è³½ä»¥ "Race X" é–‹é ­çš„è¡Œä½œç‚ºåˆ†éš”ï¼ˆæ ¹æ“šä½ æä¾›çš„æ ¼å¼ï¼‰
        # æ­¤è™•ç°¡åŒ–ï¼šå‡è¨­ DataFrame å·²ç¶“æ˜¯ã€Œæ¯åŒ¹é¦¬ä¸€è¡Œã€çš„çµæ§‹
        # è‹¥å¯¦éš›æ ¼å¼ä¸åŒï¼Œéœ€å…ˆæ¸…æ´—ï¼ˆè¦‹ä¸‹æ–¹å‚™è¨»ï¼‰
        all_races.append(df)
    return pd.concat(all_races, ignore_index=True)

# ==============================
# 2. ç‰¹å¾µå·¥ç¨‹
# ==============================
def engineer_features(df):
    # è¤‡è£½é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
    df = df.copy()
    
    # ç›®æ¨™è®Šé‡ï¼šæ˜¯å¦è·‘å…¥å‰ä¸‰
    df['is_top3'] = df['åæ¬¡'].apply(lambda x: 1 if x in [1, 2, 3] else 0)
    
    # æ¸…ç†è³ ç‡ï¼ˆè½‰ç‚ºæ•¸å€¼ï¼‰
    df['ç¨è´è³ ç‡'] = pd.to_numeric(df['ç¨è´è³ ç‡'], errors='coerce').fillna(999)  # å†·é–€è¨­é«˜å€¼
    
    # é¨å¸« & ç·´é¦¬å¸« â†’ è½‰ç‚º IDï¼ˆç°¡å–®ç·¨ç¢¼ï¼‰
    df['jockey_id'] = pd.Categorical(df['é¨å¸«']).codes
    df['trainer_id'] = pd.Categorical(df['ç·´é¦¬å¸«']).codes
    
    # é¸æ“‡ç‰¹å¾µ
    feature_cols = [
        'å¯¦éš›è² ç£…', 'æ’ä½é«”é‡', 'æª”ä½',
        'ç¨è´è³ ç‡', 'jockey_id', 'trainer_id'
    ]
    
    # ç§»é™¤ç¼ºå¤±å€¼
    df = df.dropna(subset=feature_cols + ['is_top3'])
    
    return df, feature_cols

# ==============================
# 3. è¨“ç·´æ¨¡å‹
# ==============================
def train_and_save_model(df, feature_cols, model_path="model/model.pkl"):
    X = df[feature_cols]
    y = df['is_top3']
    
    # åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # è¨“ç·´éš¨æ©Ÿæ£®æ—
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # è©•ä¼°
    y_pred = model.predict(X_test)
    print("âœ… æ¨¡å‹æº–ç¢ºç‡:", accuracy_score(y_test, y_pred))
    print("\nğŸ“Š åˆ†é¡å ±å‘Š:")
    print(classification_report(y_test, y_pred, target_names=["æœªå…¥ä½", "å…¥ä½"]))
    
    # å„²å­˜æ¨¡å‹
    Path(model_path).parent.mkdir(exist_ok=True)
    joblib.dump(model, model_path)
    print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜è‡³: {model_path}")
    
    return model, feature_cols

# ==============================
# ä¸»ç¨‹å¼
# ==============================
if __name__ == "__main__":
    # åˆ—å‡ºä½ çš„ Excel æª”æ¡ˆ
    files = [
        "data/HKJ_local_results_20230910.xlsx",
        "data/HKJ_local_results_20230913.xlsx",
        "data/HKJ_local_results_20230917.xlsx",
        "data/HKJ_local_results_20230920.xlsx"
    ]
    
    print("ğŸ“¥ è¼‰å…¥è³½é¦¬æ•¸æ“š...")
    raw_df = load_race_results(files)
    
    print("ğŸ”§ ç‰¹å¾µå·¥ç¨‹...")
    df, features = engineer_features(raw_df)
    
    print(f"ğŸ“Š å…± {len(df)} ç­†æœ‰æ•ˆæ¨£æœ¬")
    print(f"ğŸ¯ ç‰¹å¾µ: {features}")
    
    print("\nğŸ§  è¨“ç·´æ¨¡å‹...")
    model, _ = train_and_save_model(df, features)
