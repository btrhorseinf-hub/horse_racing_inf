# train_model.py
import os
import pandas as pd
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from pathlib import Path

def main():
    # è¨­å®šè·¯å¾‘
    data_dir = "data"
    model_dir = "model"
    model_path = os.path.join(model_dir, "model.pkl")
    
    # æª¢æŸ¥ data è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        print(f"âŒ éŒ¯èª¤: '{data_dir}' è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼")
        print("è«‹å…ˆå»ºç«‹ 'data' è³‡æ–™å¤¾ï¼Œä¸¦å°‡ä½ çš„ Excel æª”æ¡ˆæ”¾å…¥å…¶ä¸­ã€‚")
        return
    
    # åˆ—å‡ºæ‰€æœ‰ .xlsx æª”æ¡ˆ
    excel_files = [f for f in os.listdir(data_dir) if f.endswith('.xlsx')]
    if not excel_files:
        print(f"âŒ éŒ¯èª¤: '{data_dir}' ä¸­æ²’æœ‰ .xlsx æª”æ¡ˆï¼")
        return
    
    print(f"ğŸ“¥ æ‰¾åˆ° {len(excel_files)} å€‹ Excel æª”æ¡ˆ: {excel_files}")
    
    # åˆä½µæ‰€æœ‰æ•¸æ“š
    all_data = []
    for file in excel_files:
        try:
            df = pd.read_excel(os.path.join(data_dir, file))
            # æ¸…ç†æ¬„ä½åç¨±ï¼ˆç§»é™¤å‰å¾Œç©ºæ ¼ï¼‰
            df.columns = df.columns.str.strip()
            all_data.append(df)
            print(f"âœ… å·²è¼‰å…¥: {file} ({len(df)} ç­†è¨˜éŒ„)")
        except Exception as e:
            print(f"âš ï¸ è·³é {file}: {e}")
    
    if not all_data:
        print("âŒ æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•æ•¸æ“šï¼")
        return
    
    df = pd.concat(all_data, ignore_index=True)
    print(f"\nğŸ“Š ç¸½å…±åˆä½µ {len(df)} ç­†è³½é¦¬è¨˜éŒ„")
    
    # å¿…è¦æ¬„ä½ï¼ˆæ ¹æ“šä½ æä¾›çš„æª”æ¡ˆï¼‰
    required_cols = ["åæ¬¡", "å¯¦éš› è² ç£…", "æ’ä½ é«”é‡", "æª”ä½", "ç¨è´ è³ ç‡", "é¨å¸«", "ç·´é¦¬å¸«"]
    
    # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
        print("å¯ç”¨æ¬„ä½:", list(df.columns))
        return
    
    # åªä¿ç•™å¿…è¦æ¬„ä½
    df = df[required_cols].copy()
    
    # æ¸…ç†æ•¸æ“š
    df = df.dropna(subset=["åæ¬¡"])  # ç§»é™¤åæ¬¡ç¼ºå¤±
    df["åæ¬¡"] = pd.to_numeric(df["åæ¬¡"], errors="coerce")
    df = df.dropna(subset=["åæ¬¡"])
    
    # ç›®æ¨™è®Šé‡ï¼šæ˜¯å¦å…¥å‰ä¸‰
    df["is_top3"] = df["åæ¬¡"].apply(lambda x: 1 if x in [1, 2, 3] else 0)
    
    # è™•ç†è³ ç‡
    df["ç¨è´ è³ ç‡"] = pd.to_numeric(df["ç¨è´ è³ ç‡"], errors="coerce")
    df["ç¨è´ è³ ç‡"] = df["ç¨è´ è³ ç‡"].fillna(999)  # å†·é–€é¦¬è¨­é«˜å€¼
    
    # é¨å¸« & ç·´é¦¬å¸«ç·¨ç¢¼
    df["jockey_id"] = pd.Categorical(df["é¨å¸«"]).codes
    df["trainer_id"] = pd.Categorical(df["ç·´é¦¬å¸«"]).codes
    
    # ç‰¹å¾µæ¬„ä½
    feature_cols = ["å¯¦éš› è² ç£…", "æ’ä½ é«”é‡", "æª”ä½", "ç¨è´ è³ ç‡", "jockey_id", "trainer_id"]
    df = df.dropna(subset=feature_cols)
    
    print(f"ğŸ”§ æœ‰æ•ˆè¨“ç·´æ¨£æœ¬æ•¸: {len(df)}")
    
    if len(df) < 10:
        print("âŒ æ•¸æ“šå¤ªå°‘ï¼Œç„¡æ³•è¨“ç·´æ¨¡å‹ï¼")
        return
    
    # æº–å‚™è¨“ç·´æ•¸æ“š
    X = df[feature_cols]
    y = df["is_top3"]
    
    # åˆ†å‰²æ•¸æ“š
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # è¨“ç·´æ¨¡å‹
    print("ğŸ§  è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹...")
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # è©•ä¼°
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… æ¸¬è©¦æº–ç¢ºç‡: {acc:.2%}")
    print("\nğŸ“Š åˆ†é¡å ±å‘Š:")
    print(classification_report(y_test, y_pred, target_names=["æœªå…¥ä½", "å…¥ä½"]))
    
    # å„²å­˜æ¨¡å‹
    Path(model_dir).mkdir(exist_ok=True)
    joblib.dump(model, model_path)
    print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜è‡³: {model_path}")
    print("\nğŸ‰ è¨“ç·´å®Œæˆï¼ç¾åœ¨å¯ä»¥éƒ¨ç½² API äº†ã€‚")

if __name__ == "__main__":
    main()